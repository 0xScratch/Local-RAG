{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de462e7-8a9a-4147-bad2-718b9a5f54fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your LangSmith API key (optional):  ········\n",
      "Enter your LangSmith Project Name (default = \"default\"):  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # load environment variables from .env file (requires `python-dotenv`)\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "if \"LANGSMITH_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\n",
    "        prompt=\"Enter your LangSmith API key (optional): \"\n",
    "    )\n",
    "if \"LANGSMITH_PROJECT\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_PROJECT\"] = getpass.getpass(\n",
    "        prompt='Enter your LangSmith Project Name (default = \"default\"): '\n",
    "    )\n",
    "    if not os.environ.get(\"LANGSMITH_PROJECT\"):\n",
    "        os.environ[\"LANGSMITH_PROJECT\"] = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6a7ef1e-2b83-4207-9d16-465513ccf3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade --quiet langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe5380d9-943b-4340-b484-58dbe752da90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cac5016-8eb4-42cc-aa05-0b8bdddf2b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in e:\\chain\\bootcamps\\decentralized_ai_bootcamp\\local-rag\\venv\\lib\\site-packages (0.4.8)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in e:\\chain\\bootcamps\\decentralized_ai_bootcamp\\local-rag\\venv\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in e:\\chain\\bootcamps\\decentralized_ai_bootcamp\\local-rag\\venv\\lib\\site-packages (from ollama) (2.11.4)\n",
      "Requirement already satisfied: anyio in e:\\chain\\bootcamps\\decentralized_ai_bootcamp\\local-rag\\venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in e:\\chain\\bootcamps\\decentralized_ai_bootcamp\\local-rag\\venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\chain\\bootcamps\\decentralized_ai_bootcamp\\local-rag\\venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in e:\\chain\\bootcamps\\decentralized_ai_bootcamp\\local-rag\\venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in e:\\chain\\bootcamps\\decentralized_ai_bootcamp\\local-rag\\venv\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\chain\\bootcamps\\decentralized_ai_bootcamp\\local-rag\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in e:\\chain\\bootcamps\\decentralized_ai_bootcamp\\local-rag\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in e:\\chain\\bootcamps\\decentralized_ai_bootcamp\\local-rag\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in e:\\chain\\bootcamps\\decentralized_ai_bootcamp\\local-rag\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.4.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in e:\\chain\\bootcamps\\decentralized_ai_bootcamp\\local-rag\\venv\\lib\\site-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "777d2309-f226-4d90-a0f8-154015681ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"gemma3:4b\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfececf4-ca54-424e-a76a-331c3764f6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Extract the desired information from the following passage.\n",
    "\n",
    "Only extract the properties mentioned in the 'Classification' function.\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "class Classification(BaseModel):\n",
    "    sentiment: str = Field(description=\"The sentiment of the text\")\n",
    "    aggressiveness: int = Field(\n",
    "        description=\"How aggressive the text is on a scale from 1 to 10\"\n",
    "    )\n",
    "    language: str = Field(description=\"The language the text is written in\")\n",
    "\n",
    "\n",
    "# Structured LLM\n",
    "structured_llm = llm.with_structured_output(Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ea93ab8-7fde-4eef-b7b4-19752b2a7855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentiment='positive', aggressiveness=0, language='Spanish')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "response = structured_llm.invoke(prompt)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a581cb4e-4251-4a8c-b77a-4ae5a9af316e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'anger', 'aggressiveness': 1, 'language': 'Spanish'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Estoy muy enojado con vos! Te voy a dar tu merecido!\"\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "response = structured_llm.invoke(prompt)\n",
    "\n",
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a17eff4-2244-4c85-abd9-050042662782",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(BaseModel):\n",
    "    sentiment: str = Field(..., enum=[\"happy\", \"neutral\", \"sad\"])\n",
    "    aggressiveness: int = Field(\n",
    "        ...,\n",
    "        description=\"describes how aggressive the statement is, the higher the number the more aggressive\",\n",
    "        enum=[1, 2, 3, 4, 5],\n",
    "    )\n",
    "    language: str = Field(\n",
    "        ..., enum=[\"spanish\", \"english\", \"french\", \"german\", \"italian\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60f44d34-a48f-4f6a-acdb-915a5a9d4695",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Extract the desired information from the following passage.\n",
    "\n",
    "Only extract the properties mentioned in the 'Classification' function.\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOllama(model=\"gemma3:4b\", temperature=0).with_structured_output(\n",
    "    Classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adf422e6-d5ac-4dff-9577-38719a7da516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentiment='happy', aggressiveness=1, language='spanish')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "151a7681-be7a-4a23-9d68-e8cb829112d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentiment='sad', aggressiveness=1, language='spanish')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Estoy muy enojado con vos! Te voy a dar tu merecido!\"\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c117412d-82b3-4997-a6ad-7affaa680970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentiment='neutral', aggressiveness=1, language='english')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Weather is ok here, I can go outside without much more than a coat\"\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4416d273-73c0-4b12-9e6c-4f25d076556c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
